{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Pandas for data frames\n",
    "import numpy as np # Standard\n",
    "import seaborn as sns # Data visualization\n",
    "import matplotlib.pyplot as plt # Plotting\n",
    "import sklearn # Machine learning library\n",
    "import sklearn.preprocessing as preprocess # Preprocessing nulls\n",
    "from sklearn.linear_model import LogisticRegression #Logistic Regression\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forests\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data file in from a CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:\\\\Users\\\\Tom\\\\Documents\\\\Titanic\\\\train.csv\") # Read in training dataset\n",
    "test = pd.read_csv(\"C:\\\\Users\\\\Tom\\\\Documents\\\\Titanic\\\\test.csv\") # Read in testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing any type of modeling, I want to take a look at the dataset. The key variable here is \"Survived\". Other variables that might be useful are sex, Age, sibsp (sibling or spouse), parch (parent or child), fare price, and destination embarked (C = Cherbourg, Q = Queenstown, S = Southampton). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to check for null values. In this case, most of the nulls are in age (177) and cabin (687)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could drop cabin, but there is some nice information there. First, I want to check to see if cabin is redundant with passenger class. For example, if all first class passengers had cabins and only first class passengers had cabins, I could drop cabin as a column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1     40\n",
       "2    168\n",
       "3    479\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouped nulls by passenger class to see if all first class had cabins.\n",
    "train[train['Cabin'].isnull()].groupby('Pclass').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    176\n",
       "2     16\n",
       "3     12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checked to see if 2nd and 3rd class passengers had cabins.\n",
    "train.groupby('Pclass').size() - train[train['Cabin'].isnull()].groupby('Pclass').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaced cabins with a cabin level. NaNs for level have 'n'. \n",
    "train['Cabin_Level'] = train['Cabin'].str[0].fillna('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to Encyclopedia Titanica, both of the null passengers embarked at Southampton. \n",
    "# https://www.encyclopedia-titanica.org/titanic-survivor/amelia-icard.html\n",
    "train[train['Embarked'].isnull()] = train[train['Embarked'].isnull()].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Next part is dealing with the missing ages. This comes from a Datacamp exercise.\n",
    "\n",
    "# Create a groupby object: by_sex_class\n",
    "by_sex_class = train.groupby(['Sex', 'Pclass'])\n",
    "\n",
    "# Write a function that imputes median\n",
    "def impute_median(series):\n",
    "    return series.fillna(series.median())\n",
    "\n",
    "# Impute age and assign to titanic['Age']\n",
    "train['Age'] = by_sex_class['Age'].transform(impute_median)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         0\n",
       "Cabin_Level      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check to make sure all missing values are taken care of. Cabin won't be in any of the models, so we're good.\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am doing the same methods for testing that I did for training. Is this the right way to handle missing data for testing? Concerned about data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all of the above for the test data set\n",
    "# Replaced cabins with a cabin level. NaNs for level have 'n'. \n",
    "test['Cabin_Level'] = test['Cabin'].str[0].fillna('N')\n",
    "\n",
    "# Create a groupby object: by_sex_class\n",
    "by_sex_class = test.groupby(['Sex', 'Pclass'])\n",
    "\n",
    "# Write a function that imputes median\n",
    "def impute_median(series):\n",
    "    return series.fillna(series.median())\n",
    "\n",
    "# Impute age and assign to titanic['Age']\n",
    "test['Age'] = by_sex_class['Age'].transform(impute_median)\n",
    "\n",
    "# Do the same thing for 'Fare' on test data\n",
    "test['Fare'] = by_sex_class['Fare'].transform(impute_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_Level\n",
       "A     15\n",
       "B     47\n",
       "C     59\n",
       "D     33\n",
       "E     32\n",
       "F     13\n",
       "G      4\n",
       "N    687\n",
       "T      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('Cabin_Level').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no deck 'T' on the Titanic, so replacing that with 'N':\n",
    "train[train['Cabin_Level'] == 'T'] = train[train['Cabin_Level'] == 'T'].replace('T', 'N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_Level\n",
       "A     15\n",
       "B     47\n",
       "C     59\n",
       "D     33\n",
       "E     32\n",
       "F     13\n",
       "G      4\n",
       "N    688\n",
       "dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('Cabin_Level').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns not needed in the model. \n",
    "X_train = train.drop(['Survived', 'PassengerId', 'Name', 'Cabin', 'Ticket'], 1) # 1 is to specify columns\n",
    "Y_train = train['Survived']\n",
    "X_test = test.drop(['PassengerId', 'Cabin', 'Name', 'Ticket'], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform categorical variables to integers\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing age, fare columns\n",
    "from scipy import stats\n",
    "X_train['Fare'] = stats.zscore(X_train['Fare'])\n",
    "X_train['Age'] = stats.zscore(X_train['Age'])\n",
    "X_test['Fare'] = stats.zscore(X_test['Fare'])\n",
    "X_test['Age'] = stats.zscore(X_test['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_log = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random forest model\n",
    "random_forest = RandomForestClassifier(n_estimators=1000)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create kNN model\n",
    "knn = sklearn.neighbors.KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission = pd.DataFrame([test['PassengerId'], y_pred_log]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file to CSV\n",
    "Submission.to_csv(\"C:\\\\Users\\\\Tom\\\\Documents\\\\Titanic\\\\Submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
